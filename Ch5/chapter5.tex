\graphicspath{ {./Ch5/}  } 
\DeclareGraphicsExtensions{.png,.pdf,.jpg}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation Performance}

Table 1 shows parameters from Section II.B for each implementation of autonomic closure considered here. Together these allow a systematic assessment of the effects of various implementation choices on the performance of autonomic closure. Cases are grouped into three categories. The first category (Cases 1a-4b) primarily examines effects of series truncation order, inclusion of pressure, and the relative training ratio $M/N$, while the bounding box size $n^3$ and the number $M$ of training points vary as needed to obtain these  $M/N$ values. The second (Cases 5a-6b) primarily examines effects of colocated and non-colocated implementations, with and without pressure, keeping the bounding box at its largest possible size and the relative training ratio  $M/N$ roughly comparable to the first category. The third category (Cases 7a-8b) primarily examines highly local implementations and series truncation order, with relative training ratios $M/N$  necessarily low due to the small bounding box sizes. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computational times} 

The resulting single-core computational time for each implementation of autonomic closure is given in Table 1. We used standard LAPACK routines that take advantage of symmetry to speed the inversion in (9). As noted in Section III.F, the computational cost for autonomic closure is determined primarily by the time needed to build the $\widehat{\mathbf{V}}$  matrix, which is expected to scale as $M \cdot N$, and the time needed for the damped least-squares solution in (9) for the coefficients $\mathbf{h}_{ij}$, which is expected to scale as $N^2$. In comparison, the time to construct  $\tau_{ij}$ from  $\mathbf{h}_{ij}$  and  $\widetilde{\mathbf{V}}$  via (7) is presumed to be negligible. If these assumptions are correct then the combined computational times $T$ in Table 1 would be expected to scale as
%
%    EQUATION   %  
%%%%%%%%%%%%%%%%%
\begin{equation}
	\label{E:12}
	T \approx c_1 (M \cdot N) + c_2 (N^2).
\end{equation}
%%%%%%%%%%%%%%%%%
%
%         
For the cases in Table 1 the best fit to this scaling is with $c_1 \approx 1.8 \times 10^{-3}$  and  $c_2 \approx 2.0 \times 10^{-3}$. Comparison of the resulting scaling in (12) and the actual computational times is shown in Fig. 5. Note Cases 5a,b have been excluded since their large matrix sizes introduce additional time for memory management that are not representative of practical implementations. The fact that the scaling prefactors $c_1$  and  $c_2$ are nearly equal was unexpected in Section III.F and likely reflects the substantial speedup available in LAPACK for the symmetric matrix inversion compared to a brute force inversion.
It is apparent in Fig. 5 that (12) provides reasonable scaling of $T$ over nearly three orders of magnitude, and can therefore be used to understand how the implementation parameters $N$ and $M$ affect the computational time. For this purpose it is useful to rearrange (12) as
%
%    EQUATION   %  
%%%%%%%%%%%%%%%%%
\begin{equation}
	\label{E:13}
	T \approx c_2 N^2 \bigg[ 1 + \frac{c_1}{c_2} M/N \bigg] ,
\end{equation}
%%%%%%%%%%%%%%%%%
%
%         
where  $M/N$ is the number of training points per degree of freedom in $F_{ij}$. Since $c_1/c_2$  is nearly one, it is only when $M/N \gg 1$  that the number $M$ of training points significantly affects the computational time, and when  $M/N \ll 1$ the computational time simply scales as $N^2$. It will be seen in Section IV.E that maintaining the high accuracy available via autonomic closure requires $M/N \approx O(4)$, with little benefit gained from increasing $M/N$  beyond this. As a result, from (13) the computational time for such implementations of autonomic closure scales roughly as $T \approx c_1 M \cdot N$, indicating that the time to build the $\widehat{\mathbf{V}}$ matrix is the limiting step.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Local vs nonlocal implementations} 

As noted in Section II.B, large bounding boxes allow for larger numbers $M$ of widely spaced (and thus more independent) training points, which provide more information for determining $F_{ij}$  via $\mathbf{h}_{ij}$. However, increasingly larger bounding boxes contain increasingly different local turbulence states than that which applies at the bounding box center point $\mathbf{x}$, and thus yield coefficients $\mathbf{h}_{ij}$  that are influenced by states other than that at $\mathbf{x}$. On the other hand, increasingly smaller bounding boxes provide a more-local implementation that assures training points are relevant to the local turbulence state at $\mathbf{x}$, but they inherently limit the number $M$ of available training points and their relative independence.  

To understand the performance of local (small $n^3$) and nonlocal (large $n^3$) implementations of autonomic closure, Fig. 6 shows probability densities of a typical subgrid stress component  $\tau_{ij}$ and the subgrid production $P$, and the scale-dependent support-density metrics $M_1$ and $M_2$  comparing the accuracy in the support-densities of the subgrid production fields. The red curves show the performance of local implementations (Cases 3a vs 4a) and the blue curves are from nonlocal implementations (Cases 6a vs 6b). Cases 3a and 6a have the same number $M/N$  of training points per degree of freedom, as do Cases 4a and 6b, and all these cases are second-order velocity-only implementations, so these comparisons are indicative of the effects of local versus nonlocal implementations. 

In Fig. 6 it is apparent in both $M_1$  and $M_2$  that the local implementations give more accurate results for the support on which large magnitudes of subgrid production are concentrated than do the nonlocal implementations. Support-density correlations $M_1$ for the local implementations are as high as $98\%$ and rms errors $M_2$  decrease to less than $2.3\%$  at the largest scale-ratio, while for the nonlocal implementations the correlations $M_1$  only reach $94\%$ and rms errors $M_2$  decrease only to $4\%$. The pdfs in Fig. 6 show that, for the same $M/N$  value, the local implementations give better representation of  $\tau_{ij}$ and $P$, especially in the tails that correspond to large magnitudes, than do the corresponding nonlocal implementations. Moreover, note in Table 1 that the computational cost is the same for Cases 3a and 6a, and for Cases 4a and 6b, since  $M/N$ is the same for each pair, as discussed in Section IV.A. We conclude that, all other factors being the same, local implementations are more accurate than nonlocal ones. 

Figure 6 shows relatively little difference in accuracy between the two local implementations (Cases 3a and 4a) or between the two nonlocal implementations (Cases 6a and 6b). Since each pair differs primarily in its  $M/N$ value, there apparently is little benefit in autonomic closure from increasing the number of training points per degree of freedom from  $M/N = 4$ to  $M/N = 8$. Additionally, the greater separation  $(V_B/M)^{1/3}$ between training points in the nonlocal implementations (Cases 6a and 6b) compared to that in the local implementations also appears to provide little benefit. These effects will be examined in greater detail in Section IV.E.

%
%    FIGURE     % 
%%%%%%%%%%%%%%%%%
\begin{figure}
	\begin{center}
	\includegraphics[width=\maxwidth{4in}]{Fig6.pdf}
	\caption{ Comparison of nonlocal (blue) and local (red) implementations of autonomic closure; (top) pdfs of (left) typical subgrid stress component $\tau_{12}$ and (right) subgrid production $P$ versus (black) exact results, and (bottom) $M_1$ and $M_2$ variations with scale ratio $\Delta_{\Gamma}/\widetilde{\Delta}$ for subgrid production field. }
	\label{F:6}
	\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Velocity-pressure vs velocity-only implementations}

The Volterra series used here for $F_{ij}$  in (5) and (6) consists of all possible products up to second order among the variables on a  $3 \times 3 \times 3$ stencil, including all multi-variable products. When only single-point products are included, then $F_{ij}$  has $N = 379$ degrees of freedom for a velocity-pressure implementation and $N = 244$ for a velocity-only implementation. As noted in Section II.B, including pressure increases nonlocal effects in the nonparametric representation $F_{ij}$  beyond the nonlocality available from the velocities on the stencil. At the same time, a velocity-pressure formulation also increases the number of degrees of freedom $N$. 

%
%    FIGURE     % 
%%%%%%%%%%%%%%%%%
\begin{figure}
	\begin{center}
	\includegraphics[width=\maxwidth{4in}]{Fig7.pdf}
	\caption{ Comparison of velocity-pressure (blue) vs. velocity-only (red) implementations of autonomic closure; (top) pdfs of (left) typical subgrid stress component $\tau_{12}$ and (right) subgrid production $P$ versus (black) exact results, and (bottom) $M_1$ and $M_2$ variation in (11a,b) with scale ratio $\Delta_{\Gamma}/\widetilde{\Delta}$. }
	\label{F:7}
	\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%
%

Figure 7 compares several velocity-pressure implementations with corresponding velocity-only implementations (Cases 1a vs 1b, 2a vs 2b, 3a vs 3b, 4a vs 4b, and 5a vs 5b). Each pair has the same number $M/N$  of training points per degree of freedom, and in each pair the case number ending in “b” includes pressure. In the $M_1$  and $M_2$  results, it can be seen that for first-order implementations ($N$ = 82 or 109) there is some improvement when pressure is included, but for second-order implementations ($N$ = 244 or 379) there is essentially negligible benefit from including pressure. This indicates that the improvement seen in first-order implementations when including pressure is not so much due to the addition of nonlocal effects from the pressure itself, but instead largely due to the greater number $N$ of degrees of freedom in $F_{ij}$  when an additional stencil variable is included. 

A velocity-pressure implementation does however lead to greater computational cost over the corresponding velocity-only implementation. As seen in Table 1, including pressure typically raises the computational cost by a factor of 2-4. Including pressure may thus be justified for first-order implementations, where the additional degrees of freedom provide some benefit, but not for second-order implementations, where $N$ is already large enough that a further increase in the number of degrees of freedom provides negligible benefits.

%
%    FIGURE     % 
%%%%%%%%%%%%%%%%%
\begin{figure}
	\begin{center}
	\includegraphics[width=\maxwidth{4in}]{Fig8.pdf}
	\caption{ Comparison of second-order (blue) vs. first-order (red) implementations of autonomic closure; (top) pdfs of (left) typical subgrid stress component $\tau_{12}$ and (right) subgrid production $P$ versus (black) exact results, and (bottom) $M_1$ and $M_2$ variation in (11a,b) with scale ratio $\Delta_{\Gamma}/\widetilde{\Delta}$.}
	\label{F:8}
	\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%

Additionally, note in Table 1 that noncolocated implementations (Cases 5a and 5b) lead to a large increase in $N$, and thereby to a large increase in computational time $T$, but Fig. 7 shows that they produce only very little improvement in  $M_1$ and $M_2$  or in the pdfs of  $\tau_{ij}$ or $P$. The best colocated implementations perform nearly as well, and do so at far lower computational cost.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{First-order vs second-order implementations}

Table 1 and (13) show there is a substantial increase in computational cost from the increase in $N$ when second-order terms are included in the Volterra series for  $F_{ij}$ in (5) and (6). This can be seen by comparing the computational times for Cases 1a vs 3a, 1b vs 3b, 2a vs 4a, and 2b vs 4b. Each pair has the same number  $M/N$ of training points per degree-of-freedom. Including second-order terms is seen to increase computational cost by a factor of 14-30 over the cost for a corresponding first-order implementation, consistent with the scaling in (13).  

Figure 8 compares the performance of first-order and second-order implementations via pdfs of the subgrid stress and production, and the support-density metrics  $M_1$ and $M_2$ for the subgrid production fields. It is evident in the pdfs of  $\tau_{ij}$ and $P$ and in $M_1$   and $M_2$  that the second-order (blue) implementations give more accurate results for  $\tau_{ij}$ and $P$ than do first-order (red) implementations. Part of the benefit from second-order implementations is simply due to the greater number $N$ of degrees of freedom in  $F_{ij}$ when second-order terms are retained, consistent with results found in Section IV.C. However, having seen in Section IV.C that including pressure in a second-order implementation provides negligible benefit, it is apparent that the advantage of these second-order implementations over the corresponding first-order implementations can be understood solely in terms of the velocities on the stencil. 

%
%    FIGURE     % 
%%%%%%%%%%%%%%%%%
\begin{figure}
	\begin{center}
	\includegraphics[width=\maxwidth{4in}]{Fig9.pdf}
	\caption{Effect of number of training points per degree of freedom in implementations of autonomic closure with $M/N \leq 1$ (blue) and $M/N \gg 1$  (red); (top) pdfs of (left) typical subgrid stress component $\tau_{12}$ and (right) subgrid production $P$ versus (black) exact results, and (bottom) $M_1$ and $M_2$ variation in (11a,b) with scale ratio $\Delta_{\Gamma}/\widetilde{\Delta}$ for subgrid production support-density fields.}
	\label{F:9}
	\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%
%

Specifically, the velocities in a first-order implementation restrict  $F_{ij}$ to sums and differences of velocity values on the $3 \times 3 \times 3$  stencil. These can account for parametric quantities such as the strain rate $S_{ij}$  and rotation rate  $R_{ij}$ components, as well as their gradients $\nabla S_{ij}$  and $\nabla R_{ij}$, all of which alone are only first-order in the velocity components on the stencil. Thus even a first-order velocity-only implementation allows this larger set of parametric quantities to be implicitly represented in $F_{ij}$  than do traditional closures that assume $\tau_{ij}$  to depend only on $S_{ij}$  and $R_{ij}$, with the coefficients $\mathbf{h}_{ij}$  at each point $\mathbf{x}$ determining the relative contributions from each quantity. 

A second-order implementation allows an even larger set of such parametric quantities, including tensor products of $S_{ij}$, $R_{ij}$,  $\nabla S_{ij}$ and $\nabla R_{ij}$, to be implicitly represented in $F_{ij}$. It is this large set of possible tensor products that makes an explicit tensor invariance-preserving parametric formulation of  $F_{ij}$ far more difficult to implement than is the primitive variable formulation in (5) and (6), for which tensor invariance properties are instead implicitly inherited in   from the test-stress training data, which intrinsically satisfies these properties. Results in Section IV.F and Section V show that the present primitive-variable formulation produces far more accurate results for  $\tau_{ij}(\mathbf{x},t)$ and $P(\mathbf{x},t)$  than do traditional prescribed closure models that explicitly enforce the tensor invariance properties of the subgrid stress.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Effect of number of training points and their separation}

As noted in Section II.B, both the number of training points and their relative independence might be expected to affect the amount of information available in the $\widehat{\mathbf{V}}$  matrix to determine the $N$ degrees of freedom in $F_{ij}$, and thereby increase its generalizability from the test scale to the LES scale. In general, large numbers $M$ of training points and increased separation $(V_B/M)^{1/3}$  between them could thus lead to improved accuracy in $\tau_{ij}(\mathbf{x},t)$  and the associated  $P(\mathbf{x},t)$. However, simply increasing both $M$ and $(V_B/M)^{1/3}$  simultaneously by making the bounding box volume  $V_B$ large was shown in Section IV.B to be ineffective, since the resulting less-local implementation then causes $\widehat{\mathbf{V}}$ to contain training points that are not relevant to the turbulence state at the bounding box center point $\mathbf{x}$. On the other hand, reducing  $V_B$ inherently limits the number of available training points and their relative separation. 

We first examine the effect of the number  $M/N$ of training points per degree of freedom 
in $F_{ij}$. Figure 9 compares the performance of implementations with $M/N \leq 1$  to those having $M/N \gg 1$. In general, cases having  $M/N \gg 1$ (red) outperform those with  $M/N \leq 1$ (blue). However, it can be seen that there is no apparent benefit from increasing $M/N$ above about 4. For instance, Cases 3a and 4a have nearly identical performance, as do Cases 1a and 2a, even though  $M/N$ in each pair are 4.0 and 8.0, respectively. The same can be seen in comparing Cases 6a and 7a in Fig. 7. Cases 7a and 8a in Fig. 9 also have nearly identical performance, even though their $M/N$ values differ by a factor of four. These results indicate that, as long as $M/N$  is sufficiently larger than one (e.g., $M/N \geq 4$), other aspects of autonomic closure including the locality gained by making the bounding box volume  $n^3$ smaller and allowing for second-order terms in $F_{ij}$  have more effect on the resulting accuracy than does the number of training points per degree of freedom.

Since the number $M$ of training points does not have a primary effect on the resulting accuracy, it may be expected that the spacing between training points, which characterizes their relative independence, also will not have a primary effect. This is supported by comparing the relative training point spacing values $(V_B/M)^{1/3}$ in Table 1. For most of these cases, the training point spacing relative to the test-scale grid spacing $\widehat{\Delta}$  does not vary widely, ranging from 1.0-1.2, yet the performance of these implementations varies widely. Cases 6a and 6b, which have spacings roughly 3-4 times larger, show performance no better than many other cases having far smaller training point separation. We conclude that training point separation by itself does not have a controlling effect on the performance of autonomic closure, as long as the bounding box volume  $V_B$ is small enough to provide a local implementation, as noted in Section IV.B.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Average subgrid dissipation rates }

The pdfs of subgrid production in Figs. 6b, 7b, 8b, and 9b show that the $P^F(\mathbf{x},t)$  fields contain large positive and negative values, which combine to produce the average subgrid production rate $\langle P^F \rangle$. For each implementation of autonomic closure in Table 1, the resulting  subgrid production fields $P^F(\mathbf{x},t)$  were averaged to obtain $\langle P^F \rangle$, and the corresponding true subgrid production fields $P(\mathbf{x},t)$   were averaged to obtain $\langle P \rangle \equiv \varepsilon$. The resulting ratio of autonomic-to-true average subgrid production $\langle P^F \rangle\ /varepsilon$  for each implementation is shown in Table 1. Since $\varepsilon > 0$ , when  $\langle P^F\rangle/ \varepsilon > 0$  then $\langle P^F \rangle > 0$, which corresponds to a net average rate of energy transfer from the resolved scales into the subgrid scales.  This can be seen in Table 1 to be the case for all these implementations of autonomic closure. 

%
%    FIGURE     % 
%%%%%%%%%%%%%%%%%
\begin{figure}
	\begin{center}
	\includegraphics[width=\maxwidth{4in}]{Fig10.eps}
	\caption{Typical comparison of (left column) true subgrid stress component field $\tau_{ij}(\mathbf{x},t)$ and subgrid production field $P(\mathbf{x},t)$ with (right column) results from recommended implementation (Case 3a) of autonomic closure; (a,c) are true fields and (b,d) are corresponding fields obtained from autonomic closure. Accuracy is comparable to Fig. 1 but at nearly 500X lower computational cost.}
	\label{F:10}
	\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%
%

For cases in Table 1 that produce $\langle P^F \rangle/\varepsilon \geq 1$, the closure implementation on average transfers energy out of the resolved scales at a rate equal to or higher than the true subgrid dissipation rate $\varepsilon$. As noted in Section I.B this is necessary (but not sufficient) for any closure to maintain computational stability.  Most implementations of autonomic closure can be seen in Table 1 to meet this requirement, with the most obvious exceptions being Cases 7a,b and 8a,b, which all have very small bounding boxes that cause $M/N \leq 1$. Those cases still produce net transfer of energy out of the resolved scales, but at a rate that is far lower than the true subgrid dissipation rate $\varepsilon$. Implementations that produce  $\langle P^F \rangle/\varepsilon$  slightly larger than one are desired since they produce net average transfer of energy out of the resolved scales at a rate just slightly higher than the true subgrid dissipation rate $\varepsilon$. As a result such implementations meet the minimum requirement for computational stability while avoiding an excessively large average subgrid production rate that could lead to reduced fidelity in a simulation. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recommended implementation}

Based on the results in Sections IV.A-F, the most accurate and efficient implementation of autonomic closure among the cases in Table 1 is Case 3a. This is a relatively local, second-order, velocity-only, colocated implementation that has been found here to be nearly as accurate as that in Ref.  \cite{king2016autonomic} (Case 5b), but at a computational cost that is $O(10^3)$ smaller.  

Typical subgrid stress fields  $\tau_{ij}^{F}(\mathbf{x},t)$ and subgrid production fields $P^{F}(\mathbf{x},t)$  from Case 3a are compared in Fig. 10 to corresponding true fields $\tau_{ij}(\mathbf{x},t)$  and $P(\mathbf{x},t)$. Of particular importance from the perspective of resolved-scale energetics and computational stability, it is apparent by comparing Figs. 10c and 10d that this implementation preserves the structural similarities in  $P(\mathbf{x},t)$ and $P^{F}(\mathbf{x},t)$  nearly as well as did the far more computationally costly implementation in Fig. 1 (Case 5b). Large positive and negative values in $P^{F}(\mathbf{x},t)$  in Fig. 10d are clustered in regions at essentially the same locations and of the same size and shape as in $P(\mathbf{x},t)$  in Fig. 10c. 

%
%    FIGURE     % 
%%%%%%%%%%%%%%%%%
\begin{figure}
	\begin{center}
	\includegraphics[width=\maxwidth{4in}]{Fig11.pdf}
	\caption{Comparison of probability densities for subgrid stress component fields $\tau_{ij}(\mathbf{x},t)$ from $a priori$ tests of autonomic closure, showing resulting distributions for true subgrid stress fields (black) and from recommended implementation (Case 3a) of autonomic closure (red).}
	\label{F:11}
	\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%
%
%
%    FIGURE     % 
%%%%%%%%%%%%%%%%%
\begin{figure}
	\begin{center}
	\includegraphics[width=\maxwidth{4in}]{Fig12.pdf}
	\caption{Comparison of probability densities for subgrid production field $P(\mathbf{x},t)$ from $a priori$ tests of autonomic closure, showing results for true subgrid production fields (black) and from recommended implementation (Case 3a) of autonomic closure (red).}
	\label{F:12}
	\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%
%

Figure 11 compares probability densities of the subgrid stress fields $\tau_{ij}^{F}(\mathbf{x},t)$  from Case 3a with corresponding results for the true fields $\tau_{ij}(\mathbf{x},t)$. It is apparent that this implementation of autonomic closure accurately produces nearly all aspects of these probability distributions, including the tails of these distributions. Figure 12 similarly compares the probability density for the subgrid production fields $P^{F}(\mathbf{x},t)$  from Case 3a with the corresponding distribution for the true fields $P(\mathbf{x},t)$. It is again apparent that this implementation of autonomic closure accurately produces the probability distribution of subgrid production values, including the tails of the distribution that correspond to large positive values (forward scatter) and negative values (backscatter) in the subgrid production fields. Also, Figs. 6-9 showed that Case 3a provides the most accurate representation of spatial structure in the subgrid production fields, as quantified by  $M_1$ and $M_2$, among computationally efficient implementations in Table 1. 

Moreover, Table 1 shows the average subgrid production from Case 3a to be $\langle P^F \rangle \approx 1.08 \varepsilon$, indicating that this implementation transfers energy out of the resolved scales at a net average rate just slightly higher than the true average subgrid dissipation rate $\varepsilon$. As a result, this implementation satisfies the minimum requirement for computational stability while avoiding an excessively large average subgrid production rate that could negatively impact fidelity when implemented in a large eddy simulation.

Based on the average subgrid production rate in Table 1 and on the statistical and structural comparisons of  $\tau_{ij}^{F}(\mathbf{x},t)$ and $P^{F}(\mathbf{x},t)$  with  $\tau_{ij}(\mathbf{x},t)$ and  $P(\mathbf{x},t)$ in Figs. 6-12, the recommended implementation of autonomic closure (Case 3a) satisfies the criteria noted in Section I.B for any subgrid closure to be accurate across essentially all resolved scales and to potentially provide computational stability in a simulation. This implementation of autonomic closure is accurate and efficient enough for practical use in large eddy simulations, allowing future $a posteriori$ tests to assess its stability when used in an LES code.




