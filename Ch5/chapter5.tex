\graphicspath{ {./Ch5/}  } 
\DeclareGraphicsExtensions{.png,.pdf,.jpg}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementation Performance}

Table 1 shows parameters from Section II.B for each implementation of autonomic closure considered here. Together these allow a systematic assessment of the effects of various implementation choices on the performance of autonomic closure. Cases are grouped into three categories. The first category (Cases 1a-4b) primarily examines effects of series truncation order, inclusion of pressure, and the relative training ratio  , while the bounding box size n3 and the number M of training points vary as needed to obtain these   values. The second (Cases 5a-6b) primarily examines effects of colocated and non-colocated implementations, with and without pressure, keeping the bounding box at its largest possible size and the relative training ratio   roughly comparable to the first category. The third category (Cases 7a-8b) primarily examines highly local implementations and series truncation order, with relative training ratios   necessarily low due to the small bounding box sizes. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computational times} 

The resulting single-core computational time for each implementation of autonomic closure is given in Table 1. We used standard LAPACK routines that take advantage of symmetry to speed the inversion in (9). As noted in Section III.F, the computational cost for autonomic closure is determined primarily by the time needed to build the   matrix, which is expected to scale as  , and the time needed for the damped least-squares solution in (9) for the coefficients  , which is expected to scale as  . In comparison, the time to construct   from   and   via (7) is presumed to be negligible. If these assumptions are correct then the combined computational times T in Table 1 would be expected to scale as

.                                                (12)
For the cases in Table 1 the best fit to this scaling is with   and  . Comparison of the resulting scaling in (12) and the actual computational times is shown in Fig. 5. Note Cases 5a,b have been excluded since their large matrix sizes introduce additional time for memory management that are not representative of practical implementations. The fact that the scaling prefactors   and   are nearly equal was unexpected in Section III.F and likely reflects the substantial speedup available in LAPACK for the symmetric matrix inversion compared to a brute force inversion.
It is apparent in Fig. 5 that (12) provides reasonable scaling of T over nearly three orders of magnitude, and can therefore be used to understand how the implementation parameters N and M affect the computational time. For this purpose it is useful to rearrange (12) as
    ,                                              (13)
where   is the number of training points per degree of freedom in  . Since   is nearly one, it is only when   that the number M of training points significantly affects the computational time, and when   the computational time simply scales as  . It will be seen in Section IV.E that maintaining the high accuracy available via autonomic closure requires  , with little benefit gained from increasing   beyond this. As a result, from (13) the computational time for such implementations of autonomic closure scales roughly as  , indicating that the time to build the   matrix is the limiting step.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Local vs nonlocal implementations} 

As noted in Section II.B, large bounding boxes allow for larger numbers M of widely spaced (and thus more independent) training points, which provide more information for determining   via  . However, increasingly larger bounding boxes contain increasingly different local turbulence states than that which applies at the bounding box center point x, and thus yield coefficients   that are influenced by states other than that at x. On the other hand, increasingly smaller bounding boxes provide a more-local implementation that assures training points are relevant to the local turbulence state at x, but they inherently limit the number M of available training points and their relative independence.  

To understand the performance of local (small  ) and nonlocal (large  ) implementations of autonomic closure, Fig. 6 shows probability densities of a typical subgrid stress component   and the subgrid production P, and the scale-dependent support-density metrics   and   comparing the accuracy in the support-densities of the subgrid production fields. The red curves show the performance of local implementations (Cases 3a vs 4a) and the blue curves are from nonlocal implementations (Cases 6a vs 6b). Cases 3a and 6a have the same number   of training points per degree of freedom, as do Cases 4a and 6b, and all these cases are second-order velocity-only implementations, so these comparisons are indicative of the effects of local versus nonlocal implementations. 

In Fig. 6 it is apparent in both   and   that the local implementations give more accurate results for the support on which large magnitudes of subgrid production are concentrated than do the nonlocal implementations. Support-density correlations M1 for the local implementations are as high as $98\%$ and rms errors   decrease to less than 2.3 at the largest scale-ratio, while for the nonlocal implementations the correlations   only reach 94 and rms errors   decrease only to 4. The pdfs in Fig. 6 show that, for the same   value, the local implementations give better representation of   and P, especially in the tails that correspond to large magnitudes, than do the corresponding nonlocal implementations. Moreover, note in Table 1 that the computational cost is the same for Cases 3a and 6a, and for Cases 4a and 6b, since   is the same for each pair, as discussed in Section IV.A. We conclude that, all other factors being the same, local implementations are more accurate than nonlocal ones. 

Figure 6 shows relatively little difference in accuracy between the two local implementations (Cases 3a and 4a) or between the two nonlocal implementations (Cases 6a and 6b). Since each pair differs primarily in its   value, there apparently is little benefit in autonomic closure from increasing the number of training points per degree of freedom from   to  . Additionally, the greater separation   between training points in the nonlocal implementations (Cases 6a and 6b) compared to that in the local implementations also appears to provide little benefit. These effects will be examined in greater detail in Section IV.E.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Velocity-pressure vs velocity-only implementations}

The Volterra series used here for   in (5) and (6) consists of all possible products up to second order among the variables on a   stencil, including all multi-variable products. When only single-point products are included, then   has N = 379 degrees of freedom for a velocity-pressure implementation and N = 244 for a velocity-only implementation. As noted in Section II.B, including pressure increases nonlocal effects in the nonparametric representation   beyond the nonlocality available from the velocities on the stencil. At the same time, a velocity-pressure formulation also increases the number of degrees of freedom N. 

Figure 7 compares several velocity-pressure implementations with corresponding velocity-only implementations (Cases 1a vs 1b, 2a vs 2b, 3a vs 3b, 4a vs 4b, and 5a vs 5b). Each pair has the same number   of training points per degree of freedom, and in each pair the case number ending in “b” includes pressure. In the   and   results, it can be seen that for first-order implementations (N = 82 or 109) there is some improvement when pressure is included, but for second-order implementations (N = 244 or 379) there is essentially negligible benefit from including pressure. This indicates that the improvement seen in first-order implementations when including pressure is not so much due to the addition of nonlocal effects from the pressure itself, but instead largely due to the greater number N of degrees of freedom in   when an additional stencil variable is included. 

A velocity-pressure implementation does however lead to greater computational cost over the corresponding velocity-only implementation. As seen in Table 1, including pressure typically raises the computational cost by a factor of 2-4. Including pressure may thus be justified for first-order implementations, where the additional degrees of freedom provide some benefit, but not for second-order implementations, where N is already large enough that a further increase in the number of degrees of freedom provides negligible benefits.

Additionally, note in Table 1 that noncolocated implementations (Cases 5a and 5b) lead to a large increase in N, and thereby to a large increase in computational time T, but Fig. 7 shows that they produce only very little improvement in   and   or in the pdfs of   or P. The best colocated implementations perform nearly as well, and do so at far lower computational cost.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{First-order vs second-order implementations}

Table 1 and (13) show there is a substantial increase in computational cost from the increase in N when second-order terms are included in the Volterra series for   in (5) and (6). This can be seen by comparing the computational times for Cases 1a vs 3a, 1b vs 3b, 2a vs 4a, and 2b vs 4b. Each pair has the same number   of training points per degree-of-freedom. Including second-order terms is seen to increase computational cost by a factor of 14-30 over the cost for a corresponding first-order implementation, consistent with the scaling in (13).  

Figure 8 compares the performance of first-order and second-order implementations via pdfs of the subgrid stress and production, and the support-density metrics   and  for the subgrid production fields. It is evident in the pdfs of   and P and in   and   that the second-order (blue) implementations give more accurate results for   and P than do first-order (red) implementations. Part of the benefit from second-order implementations is simply due to the greater number N of degrees of freedom in   when second-order terms are retained, consistent with results found in Section IV.C. However, having seen in Section IV.C that including pressure in a second-order implementation provides negligible benefit, it is apparent that the advantage of these second-order implementations over the corresponding first-order implementations can be understood solely in terms of the velocities on the stencil. 

Specifically, the velocities in a first-order implementation restrict   to sums and differences of velocity values on the   stencil. These can account for parametric quantities such as the strain rate   and rotation rate   components, as well as their gradients   and  , all of which alone are only first-order in the velocity components on the stencil. Thus even a first-order velocity-only implementation allows this larger set of parametric quantities to be implicitly represented in   than do traditional closures that assume   to depend only on   and  , with the coefficients   at each point x determining the relative contributions from each quantity. 

A second-order implementation allows an even larger set of such parametric quantities, including tensor products of  ,  ,   and  , to be implicitly represented in  . It is this large set of possible tensor products that makes an explicit tensor invariance-preserving parametric formulation of   far more difficult to implement than is the primitive variable formulation in (5) and (6), for which tensor invariance properties are instead implicitly inherited in   from the test-stress training data, which intrinsically satisfies these properties. Results in Section IV.F and Section V show that the present primitive-variable formulation produces far more accurate results for   and   than do traditional prescribed closure models that explicitly enforce the tensor invariance properties of the subgrid stress.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Effect of number of training points and their separation}

As noted in Section II.B, both the number of training points and their relative independence might be expected to affect the amount of information available in the   matrix to determine the N degrees of freedom in  , and thereby increase its generalizability from the test scale to the LES scale. In general, large numbers M of training points and increased separation   between them could thus lead to improved accuracy in   and the associated  . However, simply increasing both M and   simultaneously by making the bounding box volume   large was shown in Section IV.B to be ineffective, since the resulting less-local implementation then causes   to contain training points that are not relevant to the turbulence state at the bounding box center point x. On the other hand, reducing   inherently limits the number of available training points and their relative separation. 

We first examine the effect of the number   of training points per degree of freedom 
in  . Figure 9 compares the performance of implementations with   to those having  . In general, cases having   (red) outperform those with   (blue). However, it can be seen that there is no apparent benefit from increasing  above about 4. For instance, Cases 3a and 4a have nearly identical performance, as do Cases 1a and 2a, even though   in each pair are 4.0 and 8.0, respectively. The same can be seen in comparing Cases 6a and 7a in Fig. 7. Cases 7a and 8a in Fig. 9 also have nearly identical performance, even though their  values differ by a factor of four. These results indicate that, as long as   is sufficiently larger than one (e.g.,  ), other aspects of autonomic closure including the locality gained by making the bounding box volume   smaller and allowing for second-order terms in   have more effect on the resulting accuracy than does the number of training points per degree of freedom.

Since the number M of training points does not have a primary effect on the resulting accuracy, it may be expected that the spacing between training points, which characterizes their relative independence, also will not have a primary effect. This is supported by comparing the relative training point spacing values   in Table 1. For most of these cases, the training point spacing relative to the test-scale grid spacing   does not vary widely, ranging from 1.0-1.2, yet the performance of these implementations varies widely. Cases 6a and 6b, which have spacings roughly 3-4 times larger, show performance no better than many other cases having far smaller training point separation. We conclude that training point separation by itself does not have a controlling effect on the performance of autonomic closure, as long as the bounding box volume   is small enough to provide a local implementation, as noted in Section IV.B.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Average subgrid dissipation rates }

The pdfs of subgrid production in Figs. 6b, 7b, 8b, and 9b show that the   fields contain large positive and negative values, which combine to produce the average subgrid production rate  . For each implementation of autonomic closure in Table 1, the resulting   subgrid production fields   were averaged to obtain  , and the corresponding true subgrid production fields   were averaged to obtain  . The resulting ratio of autonomic-to-true average subgrid production   for each implementation is shown in Table 1. Since  , when   then  , which corresponds to a net average rate of energy transfer from the resolved scales into the subgrid scales.  This can be seen in Table 1 to be the case for all these implementations of autonomic closure. 

For cases in Table 1 that produce  , the closure implementation on average transfers energy out of the resolved scales at a rate equal to or higher than the true subgrid dissipation rate  . As noted in Section I.B this is necessary (but not sufficient) for any closure to maintain computational stability.  Most implementations of autonomic closure can be seen in Table 1 to meet this requirement, with the most obvious exceptions being Cases 7a,b and 8a,b, which all have very small bounding boxes that cause  . Those cases still produce net transfer of energy out of the resolved scales, but at a rate that is far lower than the true subgrid dissipation rate  . Implementations that produce   slightly larger than one are desired since they produce net average transfer of energy out of the resolved scales at a rate just slightly higher than the true subgrid dissipation rate  . As a result such implementations meet the minimum requirement for computational stability while avoiding an excessively large average subgrid production rate that could lead to reduced fidelity in a simulation. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recommended implementation}

Based on the results in Sections IV.A-F, the most accurate and efficient implementation of autonomic closure among the cases in Table 1 is Case 3a. This is a relatively local, second-order, velocity-only, colocated implementation that has been found here to be nearly as accurate as that in Ref. [59] (Case 5b), but at a computational cost that is   smaller.  

Typical subgrid stress fields   and subgrid production fields   from Case 3a are compared in Fig. 10 to corresponding true fields   and  . Of particular importance from the perspective of resolved-scale energetics and computational stability, it is apparent by comparing Figs. 10c and 10d that this implementation preserves the structural similarities in   and   nearly as well as did the far more computationally costly implementation in Fig. 1 (Case 5b). Large positive and negative values in   in Fig. 10d are clustered in regions at essentially the same locations and of the same size and shape as in   in Fig. 10c.   

Figure 11 compares probability densities of the subgrid stress fields   from Case 3a with corresponding results for the true fields  . It is apparent that this implementation of autonomic closure accurately produces nearly all aspects of these probability distributions, including the tails of these distributions. Figure 12 similarly compares the probability density for the subgrid production fields   from Case 3a with the corresponding distribution for the true fields  . It is again apparent that this implementation of autonomic closure accurately produces the probability distribution of subgrid production values, including the tails of the distribution that correspond to large positive values (forward scatter) and negative values (backscatter) in the subgrid production fields. Also, Figs. 6-9 showed that Case 3a provides the most accurate representation of spatial structure in the subgrid production fields, as quantified by   and  , among computationally efficient implementations in Table 1. 

Moreover, Table 1 shows the average subgrid production from Case 3a to be  , indicating that this implementation transfers energy out of the resolved scales at a net average rate just slightly higher than the true average subgrid dissipation rate  . As a result, this implementation satisfies the minimum requirement for computational stability while avoiding an excessively large average subgrid production rate that could negatively impact fidelity when implemented in a large eddy simulation.

Based on the average subgrid production rate in Table 1 and on the statistical and structural comparisons of   and   with   and   in Figs. 6-12, the recommended implementation of autonomic closure (Case 3a) satisfies the criteria noted in Section I.B for any subgrid closure to be accurate across essentially all resolved scales and to potentially provide computational stability in a simulation. This implementation of autonomic closure is accurate and efficient enough for practical use in large eddy simulations, allowing future a posteriori tests to assess its stability when used in an LES code.




